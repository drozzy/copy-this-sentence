{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_loaders_transformer import train_iterator, test_iterator, valid_iterator\n",
    "from bleu import bleu_ignore_eos\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchtext\n",
    "from torchtext.datasets import TranslationDataset, Multi30k\n",
    "from torchtext.data import Field, BucketIterator\n",
    "from tensorboardX import SummaryWriter\n",
    "import spacy\n",
    "\n",
    "import random\n",
    "import math\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "train_loader, vocab = train_iterator(device=device, batch_size=32)\n",
    "test_iterator, vocab_test = test_iterator(device=device, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, hid_dim, n_layers, n_heads, pf_dim, encoder_layer, self_attention, positionwise_feedforward, dropout, device):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.n_heads = n_heads\n",
    "        self.pf_dim = pf_dim\n",
    "        self.encoder_layer = encoder_layer\n",
    "        self.self_attention = self_attention\n",
    "        self.positionwise_feedforward = positionwise_feedforward\n",
    "        self.dropout = dropout\n",
    "        self.device = device\n",
    "        \n",
    "        self.tok_embedding = nn.Embedding(input_dim, hid_dim)\n",
    "        self.pos_embedding = nn.Embedding(1000, hid_dim)\n",
    "        \n",
    "        self.layers = nn.ModuleList([encoder_layer(hid_dim, n_heads, pf_dim, self_attention, positionwise_feedforward, dropout, device) \n",
    "                                     for _ in range(n_layers)])\n",
    "        \n",
    "        self.do = nn.Dropout(dropout)\n",
    "        \n",
    "        self.scale = torch.sqrt(torch.FloatTensor([hid_dim])).to(device)\n",
    "        \n",
    "    def forward(self, src, src_mask):\n",
    "        \n",
    "        #src = [batch size, src sent len]\n",
    "        #src_mask = [batch size, src sent len]\n",
    "        \n",
    "        pos = torch.arange(0, src.shape[1]).unsqueeze(0).repeat(src.shape[0], 1).to(self.device)\n",
    "        \n",
    "        src = self.do((self.tok_embedding(src) * self.scale) + self.pos_embedding(pos))\n",
    "        \n",
    "        #src = [batch size, src sent len, hid dim]\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            src = layer(src, src_mask)\n",
    "            \n",
    "        return src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, hid_dim, n_heads, pf_dim, self_attention, positionwise_feedforward, dropout, device):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.ln = nn.LayerNorm(hid_dim)\n",
    "        self.sa = self_attention(hid_dim, n_heads, dropout, device)\n",
    "        self.pf = positionwise_feedforward(hid_dim, pf_dim, dropout)\n",
    "        self.do = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, src, src_mask):\n",
    "        \n",
    "        #src = [batch size, src sent len, hid dim]\n",
    "        #src_mask = [batch size, src sent len]\n",
    "        \n",
    "        src = self.ln(src + self.do(self.sa(src, src, src, src_mask)))\n",
    "        \n",
    "        src = self.ln(src + self.do(self.pf(src)))\n",
    "        \n",
    "        return src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, hid_dim, n_heads, dropout, device):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_heads = n_heads\n",
    "        \n",
    "        assert hid_dim % n_heads == 0\n",
    "        \n",
    "        self.w_q = nn.Linear(hid_dim, hid_dim)\n",
    "        self.w_k = nn.Linear(hid_dim, hid_dim)\n",
    "        self.w_v = nn.Linear(hid_dim, hid_dim)\n",
    "        \n",
    "        self.fc = nn.Linear(hid_dim, hid_dim)\n",
    "        \n",
    "        self.do = nn.Dropout(dropout)\n",
    "        \n",
    "        self.scale = torch.sqrt(torch.FloatTensor([hid_dim // n_heads])).to(device)\n",
    "        \n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        \n",
    "        bsz = query.shape[0]\n",
    "        \n",
    "        #query = key = value [batch size, sent len, hid dim]\n",
    "                \n",
    "        Q = self.w_q(query)\n",
    "        K = self.w_k(key)\n",
    "        V = self.w_v(value)\n",
    "        \n",
    "        #Q, K, V = [batch size, sent len, hid dim]\n",
    "        \n",
    "        Q = Q.view(bsz, -1, self.n_heads, self.hid_dim // self.n_heads).permute(0, 2, 1, 3)\n",
    "        K = K.view(bsz, -1, self.n_heads, self.hid_dim // self.n_heads).permute(0, 2, 1, 3)\n",
    "        V = V.view(bsz, -1, self.n_heads, self.hid_dim // self.n_heads).permute(0, 2, 1, 3)\n",
    "        \n",
    "        #Q, K, V = [batch size, n heads, sent len, hid dim // n heads]\n",
    "        \n",
    "        energy = torch.matmul(Q, K.permute(0, 1, 3, 2)) / self.scale\n",
    "        \n",
    "        #energy = [batch size, n heads, sent len, sent len]\n",
    "        \n",
    "        if mask is not None:\n",
    "            energy = energy.masked_fill(mask == 0, -1e10)\n",
    "        \n",
    "        attention = self.do(F.softmax(energy, dim=-1))\n",
    "        \n",
    "        #attention = [batch size, n heads, sent len, sent len]\n",
    "        \n",
    "        x = torch.matmul(attention, V)\n",
    "        \n",
    "        #x = [batch size, n heads, sent len, hid dim // n heads]\n",
    "        \n",
    "        x = x.permute(0, 2, 1, 3).contiguous()\n",
    "        \n",
    "        #x = [batch size, sent len, n heads, hid dim // n heads]\n",
    "        \n",
    "        x = x.view(bsz, -1, self.n_heads * (self.hid_dim // self.n_heads))\n",
    "        \n",
    "        #x = [batch size, src sent len, hid dim]\n",
    "        \n",
    "        x = self.fc(x)\n",
    "        \n",
    "        #x = [batch size, sent len, hid dim]\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionwiseFeedforward(nn.Module):\n",
    "    def __init__(self, hid_dim, pf_dim, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.hid_dim = hid_dim\n",
    "        self.pf_dim = pf_dim\n",
    "        \n",
    "        self.fc_1 = nn.Conv1d(hid_dim, pf_dim, 1)\n",
    "        self.fc_2 = nn.Conv1d(pf_dim, hid_dim, 1)\n",
    "        \n",
    "        self.do = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        #x = [batch size, sent len, hid dim]\n",
    "        \n",
    "        x = x.permute(0, 2, 1)\n",
    "        \n",
    "        #x = [batch size, hid dim, sent len]\n",
    "        \n",
    "        x = self.do(F.relu(self.fc_1(x)))\n",
    "        \n",
    "        #x = [batch size, ff dim, sent len]\n",
    "        \n",
    "        x = self.fc_2(x)\n",
    "        \n",
    "        #x = [batch size, hid dim, sent len]\n",
    "        \n",
    "        x = x.permute(0, 2, 1)\n",
    "        \n",
    "        #x = [batch size, sent len, hid dim]\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, hid_dim, n_layers, n_heads, pf_dim, decoder_layer, self_attention, positionwise_feedforward, dropout, device):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.output_dim = output_dim\n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.n_heads = n_heads\n",
    "        self.pf_dim = pf_dim\n",
    "        self.decoder_layer = decoder_layer\n",
    "        self.self_attention = self_attention\n",
    "        self.positionwise_feedforward = positionwise_feedforward\n",
    "        self.dropout = dropout\n",
    "        self.device = device\n",
    "        \n",
    "        self.tok_embedding = nn.Embedding(output_dim, hid_dim)\n",
    "        self.pos_embedding = nn.Embedding(1000, hid_dim)\n",
    "        \n",
    "        self.layers = nn.ModuleList([decoder_layer(hid_dim, n_heads, pf_dim, self_attention, positionwise_feedforward, dropout, device)\n",
    "                                     for _ in range(n_layers)])\n",
    "        \n",
    "        self.fc = nn.Linear(hid_dim, output_dim)\n",
    "        \n",
    "        self.do = nn.Dropout(dropout)\n",
    "        \n",
    "        self.scale = torch.sqrt(torch.FloatTensor([hid_dim])).to(device)\n",
    "        \n",
    "    def forward(self, trg, src, trg_mask, src_mask):\n",
    "        \n",
    "        #trg = [batch_size, trg sent len]\n",
    "        #src = [batch_size, src sent len]\n",
    "        #trg_mask = [batch size, trg sent len]\n",
    "        #src_mask = [batch size, src sent len]\n",
    "        \n",
    "        pos = torch.arange(0, trg.shape[1]).unsqueeze(0).repeat(trg.shape[0], 1).to(self.device)\n",
    "                \n",
    "        trg = self.do((self.tok_embedding(trg) * self.scale) + self.pos_embedding(pos))\n",
    "        \n",
    "        #trg = [batch size, trg sent len, hid dim]\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            trg = layer(trg, src, trg_mask, src_mask)\n",
    "            \n",
    "        return self.fc(trg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, hid_dim, n_heads, pf_dim, self_attention, positionwise_feedforward, dropout, device):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.ln = nn.LayerNorm(hid_dim)\n",
    "        self.sa = self_attention(hid_dim, n_heads, dropout, device)\n",
    "        self.ea = self_attention(hid_dim, n_heads, dropout, device)\n",
    "        self.pf = positionwise_feedforward(hid_dim, pf_dim, dropout)\n",
    "        self.do = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, trg, src, trg_mask, src_mask):\n",
    "        \n",
    "        #trg = [batch size, trg sent len, hid dim]\n",
    "        #src = [batch size, src sent len, hid dim]\n",
    "        #trg_mask = [batch size, trg sent len]\n",
    "        #src_mask = [batch size, src sent len]\n",
    "                \n",
    "        trg = self.ln(trg + self.do(self.sa(trg, trg, trg, trg_mask)))\n",
    "                \n",
    "        trg = self.ln(trg + self.do(self.ea(trg, src, src, src_mask)))\n",
    "        \n",
    "        trg = self.ln(trg + self.do(self.pf(trg)))\n",
    "        \n",
    "        return trg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, pad_idx, device):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.pad_idx = pad_idx\n",
    "        self.device = device\n",
    "        \n",
    "    def make_masks(self, src, trg):\n",
    "        \n",
    "        #src = [batch size, src sent len]\n",
    "        #trg = [batch size, trg sent len]\n",
    "        \n",
    "        src_mask = (src != self.pad_idx).unsqueeze(1).unsqueeze(2)\n",
    "        \n",
    "        trg_pad_mask = (trg != self.pad_idx).unsqueeze(1).unsqueeze(3)\n",
    "\n",
    "        trg_len = trg.shape[1]\n",
    "        \n",
    "        trg_sub_mask = torch.tril(torch.ones((trg_len, trg_len), dtype=torch.uint8, device=self.device))\n",
    "        \n",
    "        trg_mask = trg_pad_mask & trg_sub_mask\n",
    "        \n",
    "        return src_mask, trg_mask\n",
    "    \n",
    "    def forward(self, src, trg):\n",
    "        \n",
    "        #src = [batch size, src sent len]\n",
    "        #trg = [batch size, trg sent len]\n",
    "                \n",
    "        src_mask, trg_mask = self.make_masks(src, trg)\n",
    "        \n",
    "        enc_src = self.encoder(src, src_mask)\n",
    "        \n",
    "        #enc_src = [batch size, src sent len, hid dim]\n",
    "                \n",
    "        out = self.decoder(trg, enc_src, trg_mask, src_mask)\n",
    "        \n",
    "        #out = [batch size, trg sent len, output dim]\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = len(vocab)\n",
    "hid_dim = 512\n",
    "n_layers = 6\n",
    "n_heads = 8\n",
    "pf_dim = 2048\n",
    "dropout = 0.1\n",
    "\n",
    "enc = Encoder(input_dim, hid_dim, n_layers, n_heads, pf_dim, EncoderLayer, SelfAttention, PositionwiseFeedforward, dropout, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dim = len(vocab)\n",
    "hid_dim = 512\n",
    "n_layers = 6\n",
    "n_heads = 8\n",
    "pf_dim = 2048\n",
    "dropout = 0.1\n",
    "\n",
    "dec = Decoder(output_dim, hid_dim, n_layers, n_heads, pf_dim, DecoderLayer, SelfAttention, PositionwiseFeedforward, dropout, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_idx = vocab.stoi['<pad>']\n",
    "EOS_TOKEN = vocab.stoi['<eos>']\n",
    "\n",
    "model = Seq2Seq(enc, dec, pad_idx, device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 79,127,134 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in model.parameters():\n",
    "    if p.dim() > 1:\n",
    "        nn.init.xavier_uniform_(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoamOpt:\n",
    "    \"Optim wrapper that implements rate.\"\n",
    "    def __init__(self, model_size, factor, warmup, optimizer):\n",
    "        self.optimizer = optimizer\n",
    "        self._step = 0\n",
    "        self.warmup = warmup\n",
    "        self.factor = factor\n",
    "        self.model_size = model_size\n",
    "        self._rate = 0\n",
    "        \n",
    "    def step(self):\n",
    "        \"Update parameters and rate\"\n",
    "        self._step += 1\n",
    "        rate = self.rate()\n",
    "        for p in self.optimizer.param_groups:\n",
    "            p['lr'] = rate\n",
    "        self._rate = rate\n",
    "        self.optimizer.step()\n",
    "        \n",
    "    def rate(self, step = None):\n",
    "        \"Implement `lrate` above\"\n",
    "        if step is None:\n",
    "            step = self._step\n",
    "        return self.factor * \\\n",
    "            (self.model_size ** (-0.5) *\n",
    "            min(step ** (-0.5), step * self.warmup ** (-1.5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = NoamOpt(hid_dim, 1, 2000,\n",
    "            torch.optim.Adam(model.parameters(), lr=0, betas=(0.9, 0.98), eps=1e-9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, clip):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for i, batch in enumerate(iterator):\n",
    "        \n",
    "        src = batch.sentence\n",
    "        trg = batch.sentence\n",
    "        \n",
    "        optimizer.optimizer.zero_grad()\n",
    "        \n",
    "        output = model(src, trg[:,1:])\n",
    "                \n",
    "        #output = [batch size, trg sent len - 1, output dim]\n",
    "        #trg = [batch size, trg sent len]\n",
    "            \n",
    "        output = output.contiguous().view(-1, output.shape[-1])\n",
    "        trg = trg[:,1:].contiguous().view(-1)\n",
    "                \n",
    "        #output = [batch size * trg sent len - 1, output dim]\n",
    "        #trg = [batch size * trg sent len - 1]\n",
    "            \n",
    "        loss = criterion(output, trg)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    avg_bleu = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for i, batch in enumerate(iterator):\n",
    "\n",
    "            src = batch.sentence\n",
    "            trg = batch.sentence\n",
    "\n",
    "            output = model(src, trg[:,1:])\n",
    "            \n",
    "            #output = [batch size, trg sent len - 1, output dim]\n",
    "            #trg = [batch size, trg sent len]\n",
    "            \n",
    "            avg_bleu += compute_bleu(output, trg[:,1:])\n",
    "            \n",
    "            output = output.contiguous().view(-1, output.shape[-1])\n",
    "            trg = trg[:,1:].contiguous().view(-1)\n",
    "            \n",
    "            #output = [batch size * trg sent len - 1, output dim]\n",
    "            #trg = [batch size * trg sent len - 1]\n",
    "            \n",
    "            loss = criterion(output, trg)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), avg_bleu / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_bleu(hypothesis, reference):\n",
    "    hypothesis = hypothesis.argmax(dim=2)\n",
    "    \n",
    "    hypothesis = hypothesis.detach().cpu().numpy()\n",
    "    reference = reference.detach().cpu().numpy()\n",
    "    scores = []\n",
    "    for i in range(reference.shape[0]):\n",
    "        a = reference[i]\n",
    "        b = hypothesis[i]\n",
    "        score = float(bleu_ignore_eos(reference=a.tolist(), hypothesis=b.tolist(), eos_token=EOS_TOKEN))\n",
    "        scores.append(score)\n",
    "    \n",
    "    return torch.tensor(scores).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch: 001 | Time: 1m 11s| Train Loss: 7.271 | Train PPL: 1437.966 | Val. Loss: 4.370 | Val. PPL:  79.021 | Val. Avg Bleu: 0.067857\n",
      "| Epoch: 002 | Time: 1m 10s| Train Loss: 3.215 | Train PPL:  24.905 | Val. Loss: 2.095 | Val. PPL:   8.128 | Val. Avg Bleu: 0.469389\n",
      "| Epoch: 003 | Time: 1m 8s| Train Loss: 1.664 | Train PPL:   5.282 | Val. Loss: 1.345 | Val. PPL:   3.840 | Val. Avg Bleu: 0.673489\n",
      "| Epoch: 004 | Time: 1m 8s| Train Loss: 1.014 | Train PPL:   2.756 | Val. Loss: 0.992 | Val. PPL:   2.697 | Val. Avg Bleu: 0.758721\n",
      "| Epoch: 005 | Time: 1m 7s| Train Loss: 0.645 | Train PPL:   1.906 | Val. Loss: 0.824 | Val. PPL:   2.279 | Val. Avg Bleu: 0.821460\n",
      "| Epoch: 006 | Time: 1m 6s| Train Loss: 0.392 | Train PPL:   1.480 | Val. Loss: 0.775 | Val. PPL:   2.170 | Val. Avg Bleu: 0.835118\n",
      "| Epoch: 007 | Time: 1m 6s| Train Loss: 0.196 | Train PPL:   1.217 | Val. Loss: 0.728 | Val. PPL:   2.072 | Val. Avg Bleu: 0.838492\n",
      "| Epoch: 008 | Time: 1m 6s| Train Loss: 0.073 | Train PPL:   1.076 | Val. Loss: 0.736 | Val. PPL:   2.087 | Val. Avg Bleu: 0.838735\n",
      "| Epoch: 009 | Time: 1m 6s| Train Loss: 0.045 | Train PPL:   1.046 | Val. Loss: 0.730 | Val. PPL:   2.075 | Val. Avg Bleu: 0.836441\n",
      "| Epoch: 010 | Time: 1m 6s| Train Loss: 0.100 | Train PPL:   1.105 | Val. Loss: 0.754 | Val. PPL:   2.126 | Val. Avg Bleu: 0.837547\n",
      "| Epoch: 011 | Time: 1m 7s| Train Loss: 0.175 | Train PPL:   1.191 | Val. Loss: 0.751 | Val. PPL:   2.120 | Val. Avg Bleu: 0.837560\n",
      "| Epoch: 012 | Time: 1m 7s| Train Loss: 0.128 | Train PPL:   1.137 | Val. Loss: 0.744 | Val. PPL:   2.104 | Val. Avg Bleu: 0.838598\n",
      "| Epoch: 013 | Time: 1m 5s| Train Loss: 0.117 | Train PPL:   1.124 | Val. Loss: 0.753 | Val. PPL:   2.124 | Val. Avg Bleu: 0.838351\n",
      "| Epoch: 014 | Time: 1m 14s| Train Loss: 0.140 | Train PPL:   1.150 | Val. Loss: 0.763 | Val. PPL:   2.144 | Val. Avg Bleu: 0.838958\n",
      "| Epoch: 015 | Time: 1m 13s| Train Loss: 0.148 | Train PPL:   1.159 | Val. Loss: 0.757 | Val. PPL:   2.132 | Val. Avg Bleu: 0.838803\n",
      "| Epoch: 016 | Time: 1m 9s| Train Loss: 0.134 | Train PPL:   1.144 | Val. Loss: 0.779 | Val. PPL:   2.178 | Val. Avg Bleu: 0.839155\n",
      "| Epoch: 017 | Time: 1m 8s| Train Loss: 0.141 | Train PPL:   1.152 | Val. Loss: 0.763 | Val. PPL:   2.144 | Val. Avg Bleu: 0.838652\n",
      "| Epoch: 018 | Time: 1m 9s| Train Loss: 0.147 | Train PPL:   1.158 | Val. Loss: 0.774 | Val. PPL:   2.168 | Val. Avg Bleu: 0.838897\n",
      "| Epoch: 019 | Time: 1m 8s| Train Loss: 0.145 | Train PPL:   1.156 | Val. Loss: 0.799 | Val. PPL:   2.223 | Val. Avg Bleu: 0.838462\n",
      "| Epoch: 020 | Time: 1m 6s| Train Loss: 0.150 | Train PPL:   1.162 | Val. Loss: 0.799 | Val. PPL:   2.222 | Val. Avg Bleu: 0.838902\n",
      "| Epoch: 021 | Time: 1m 4s| Train Loss: 0.146 | Train PPL:   1.157 | Val. Loss: 0.790 | Val. PPL:   2.203 | Val. Avg Bleu: 0.838912\n",
      "| Epoch: 022 | Time: 1m 5s| Train Loss: 0.145 | Train PPL:   1.156 | Val. Loss: 0.800 | Val. PPL:   2.225 | Val. Avg Bleu: 0.839116\n",
      "| Epoch: 023 | Time: 1m 6s| Train Loss: 0.149 | Train PPL:   1.161 | Val. Loss: 0.829 | Val. PPL:   2.292 | Val. Avg Bleu: 0.839155\n",
      "| Epoch: 024 | Time: 1m 6s| Train Loss: 0.157 | Train PPL:   1.170 | Val. Loss: 0.821 | Val. PPL:   2.273 | Val. Avg Bleu: 0.838903\n",
      "| Epoch: 025 | Time: 1m 6s| Train Loss: 0.153 | Train PPL:   1.165 | Val. Loss: 0.845 | Val. PPL:   2.329 | Val. Avg Bleu: 0.839155\n",
      "| Epoch: 026 | Time: 1m 6s| Train Loss: 0.150 | Train PPL:   1.162 | Val. Loss: 0.817 | Val. PPL:   2.265 | Val. Avg Bleu: 0.838803\n",
      "| Epoch: 027 | Time: 1m 7s| Train Loss: 0.152 | Train PPL:   1.164 | Val. Loss: 0.824 | Val. PPL:   2.281 | Val. Avg Bleu: 0.838778\n",
      "| Epoch: 028 | Time: 1m 6s| Train Loss: 0.152 | Train PPL:   1.164 | Val. Loss: 0.832 | Val. PPL:   2.297 | Val. Avg Bleu: 0.838713\n",
      "| Epoch: 029 | Time: 1m 5s| Train Loss: 0.156 | Train PPL:   1.168 | Val. Loss: 0.841 | Val. PPL:   2.319 | Val. Avg Bleu: 0.838619\n",
      "| Epoch: 030 | Time: 1m 5s| Train Loss: 0.159 | Train PPL:   1.173 | Val. Loss: 0.849 | Val. PPL:   2.337 | Val. Avg Bleu: 0.838571\n",
      "| Epoch: 031 | Time: 1m 7s| Train Loss: 0.151 | Train PPL:   1.162 | Val. Loss: 0.845 | Val. PPL:   2.328 | Val. Avg Bleu: 0.839104\n",
      "| Epoch: 032 | Time: 1m 6s| Train Loss: 0.152 | Train PPL:   1.164 | Val. Loss: 0.858 | Val. PPL:   2.358 | Val. Avg Bleu: 0.838507\n",
      "| Epoch: 033 | Time: 1m 5s| Train Loss: 0.160 | Train PPL:   1.173 | Val. Loss: 0.863 | Val. PPL:   2.370 | Val. Avg Bleu: 0.838648\n",
      "| Epoch: 034 | Time: 1m 5s| Train Loss: 0.155 | Train PPL:   1.168 | Val. Loss: 0.860 | Val. PPL:   2.363 | Val. Avg Bleu: 0.838757\n",
      "| Epoch: 035 | Time: 1m 5s| Train Loss: 0.155 | Train PPL:   1.168 | Val. Loss: 0.826 | Val. PPL:   2.284 | Val. Avg Bleu: 0.839022\n",
      "| Epoch: 036 | Time: 1m 5s| Train Loss: 0.156 | Train PPL:   1.169 | Val. Loss: 0.869 | Val. PPL:   2.384 | Val. Avg Bleu: 0.838139\n",
      "| Epoch: 037 | Time: 1m 5s| Train Loss: 0.167 | Train PPL:   1.182 | Val. Loss: 0.878 | Val. PPL:   2.406 | Val. Avg Bleu: 0.838553\n",
      "| Epoch: 038 | Time: 1m 6s| Train Loss: 0.154 | Train PPL:   1.166 | Val. Loss: 0.867 | Val. PPL:   2.380 | Val. Avg Bleu: 0.839019\n",
      "| Epoch: 039 | Time: 1m 6s| Train Loss: 0.160 | Train PPL:   1.174 | Val. Loss: 0.879 | Val. PPL:   2.409 | Val. Avg Bleu: 0.838797\n",
      "| Epoch: 040 | Time: 1m 6s| Train Loss: 0.159 | Train PPL:   1.172 | Val. Loss: 0.873 | Val. PPL:   2.393 | Val. Avg Bleu: 0.838721\n",
      "| Epoch: 041 | Time: 1m 7s| Train Loss: 0.161 | Train PPL:   1.175 | Val. Loss: 0.875 | Val. PPL:   2.399 | Val. Avg Bleu: 0.838844\n",
      "| Epoch: 042 | Time: 1m 8s| Train Loss: 0.158 | Train PPL:   1.171 | Val. Loss: 0.887 | Val. PPL:   2.427 | Val. Avg Bleu: 0.839155\n",
      "| Epoch: 043 | Time: 1m 8s| Train Loss: 0.162 | Train PPL:   1.176 | Val. Loss: 0.888 | Val. PPL:   2.429 | Val. Avg Bleu: 0.838089\n",
      "| Epoch: 044 | Time: 1m 6s| Train Loss: 0.153 | Train PPL:   1.166 | Val. Loss: 0.888 | Val. PPL:   2.431 | Val. Avg Bleu: 0.839055\n",
      "| Epoch: 045 | Time: 1m 6s| Train Loss: 0.160 | Train PPL:   1.174 | Val. Loss: 0.878 | Val. PPL:   2.405 | Val. Avg Bleu: 0.838285\n",
      "| Epoch: 046 | Time: 1m 6s| Train Loss: 0.160 | Train PPL:   1.174 | Val. Loss: 0.899 | Val. PPL:   2.458 | Val. Avg Bleu: 0.838486\n",
      "| Epoch: 047 | Time: 1m 6s| Train Loss: 0.163 | Train PPL:   1.177 | Val. Loss: 0.894 | Val. PPL:   2.445 | Val. Avg Bleu: 0.839155\n",
      "| Epoch: 048 | Time: 1m 6s| Train Loss: 0.158 | Train PPL:   1.171 | Val. Loss: 0.902 | Val. PPL:   2.465 | Val. Avg Bleu: 0.838320\n",
      "| Epoch: 049 | Time: 1m 6s| Train Loss: 0.160 | Train PPL:   1.174 | Val. Loss: 0.913 | Val. PPL:   2.493 | Val. Avg Bleu: 0.838636\n",
      "| Epoch: 050 | Time: 1m 6s| Train Loss: 0.156 | Train PPL:   1.169 | Val. Loss: 0.898 | Val. PPL:   2.455 | Val. Avg Bleu: 0.839082\n",
      "| Epoch: 051 | Time: 1m 6s| Train Loss: 0.161 | Train PPL:   1.174 | Val. Loss: 0.921 | Val. PPL:   2.511 | Val. Avg Bleu: 0.838776\n",
      "| Epoch: 052 | Time: 1m 6s| Train Loss: 0.162 | Train PPL:   1.176 | Val. Loss: 0.933 | Val. PPL:   2.542 | Val. Avg Bleu: 0.838682\n",
      "| Epoch: 053 | Time: 1m 6s| Train Loss: 0.162 | Train PPL:   1.175 | Val. Loss: 0.912 | Val. PPL:   2.489 | Val. Avg Bleu: 0.839066\n",
      "| Epoch: 054 | Time: 1m 6s| Train Loss: 0.162 | Train PPL:   1.176 | Val. Loss: 0.915 | Val. PPL:   2.496 | Val. Avg Bleu: 0.839117\n",
      "| Epoch: 055 | Time: 1m 7s| Train Loss: 0.164 | Train PPL:   1.179 | Val. Loss: 0.932 | Val. PPL:   2.540 | Val. Avg Bleu: 0.838701\n",
      "| Epoch: 056 | Time: 1m 8s| Train Loss: 0.160 | Train PPL:   1.173 | Val. Loss: 0.919 | Val. PPL:   2.508 | Val. Avg Bleu: 0.838803\n",
      "| Epoch: 057 | Time: 1m 7s| Train Loss: 0.164 | Train PPL:   1.178 | Val. Loss: 0.933 | Val. PPL:   2.543 | Val. Avg Bleu: 0.837696\n",
      "| Epoch: 058 | Time: 1m 7s| Train Loss: 0.158 | Train PPL:   1.172 | Val. Loss: 0.937 | Val. PPL:   2.553 | Val. Avg Bleu: 0.839116\n",
      "| Epoch: 059 | Time: 1m 9s| Train Loss: 0.164 | Train PPL:   1.178 | Val. Loss: 0.924 | Val. PPL:   2.518 | Val. Avg Bleu: 0.838803\n",
      "| Epoch: 060 | Time: 1m 10s| Train Loss: 0.160 | Train PPL:   1.174 | Val. Loss: 0.930 | Val. PPL:   2.535 | Val. Avg Bleu: 0.838790\n",
      "| Epoch: 061 | Time: 1m 9s| Train Loss: 0.164 | Train PPL:   1.178 | Val. Loss: 0.944 | Val. PPL:   2.571 | Val. Avg Bleu: 0.838928\n",
      "| Epoch: 062 | Time: 1m 7s| Train Loss: 0.160 | Train PPL:   1.174 | Val. Loss: 0.935 | Val. PPL:   2.547 | Val. Avg Bleu: 0.837841\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch: 063 | Time: 1m 7s| Train Loss: 0.162 | Train PPL:   1.176 | Val. Loss: 0.934 | Val. PPL:   2.545 | Val. Avg Bleu: 0.838689\n",
      "| Epoch: 064 | Time: 1m 7s| Train Loss: 0.159 | Train PPL:   1.173 | Val. Loss: 0.965 | Val. PPL:   2.625 | Val. Avg Bleu: 0.838496\n",
      "| Epoch: 065 | Time: 1m 6s| Train Loss: 0.166 | Train PPL:   1.180 | Val. Loss: 0.944 | Val. PPL:   2.571 | Val. Avg Bleu: 0.839109\n",
      "| Epoch: 066 | Time: 1m 6s| Train Loss: 0.164 | Train PPL:   1.178 | Val. Loss: 0.932 | Val. PPL:   2.539 | Val. Avg Bleu: 0.838544\n",
      "| Epoch: 067 | Time: 1m 6s| Train Loss: 0.166 | Train PPL:   1.180 | Val. Loss: 0.933 | Val. PPL:   2.543 | Val. Avg Bleu: 0.838922\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-6a55630cf8f4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[0mtrain_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCLIP\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m     \u001b[0mend_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-18-f37abff1c7e0>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, iterator, optimizer, criterion, clip)\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m         \"\"\"\n\u001b[1;32m--> 102\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from itertools import count\n",
    "# N_EPOCHS = 10\n",
    "CLIP = 1\n",
    "SAVE_DIR = 'models'\n",
    "MODEL_SAVE_PATH = os.path.join(SAVE_DIR, 'transformer-seq2seq.pt')\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "PLOT = True # Set to false to disable plotting to tensorboard\n",
    "writer = SummaryWriter(comment='_transformer')\n",
    "\n",
    "\n",
    "if not os.path.isdir(f'{SAVE_DIR}'):\n",
    "    os.makedirs(f'{SAVE_DIR}')\n",
    "\n",
    "for epoch in count(1): # run forever... #range(N_EPOCHS):\n",
    "    \n",
    "    start_time = time.time()    \n",
    "    train_loss = train(model, train_loader, optimizer, criterion, CLIP)    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    valid_loss, avg_bleu = evaluate(model, test_iterator, criterion)\n",
    "    \n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), MODEL_SAVE_PATH)\n",
    "    \n",
    "    print(f'| Epoch: {epoch:03} | Time: {epoch_mins}m {epoch_secs}s| Train Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f} | Val. Loss: {valid_loss:.3f} | Val. PPL: {math.exp(valid_loss):7.3f} | Val. Avg Bleu: {avg_bleu:.6f}')\n",
    "    if PLOT:\n",
    "        writer.add_scalar('train/epoch_sec', epoch_mins * 60 + epoch_secs, epoch)\n",
    "        writer.add_scalar('train/loss', train_loss, epoch)\n",
    "        writer.add_scalar('train/ppl', math.exp(train_loss), epoch)\n",
    "        writer.add_scalar('valid/loss', valid_loss, epoch)\n",
    "        writer.add_scalar('valid/ppl', math.exp(valid_loss), epoch)\n",
    "        writer.add_scalar('valid/avg_bleu', avg_bleu, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
